@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}

@inproceedings{esser2023structure,
  title={Structure and content-guided video synthesis with diffusion models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7346--7356},
  year={2023}
}

@article{he2022latent,
  title={Latent video diffusion models for high-fidelity long video generation},
  author={He, Yingqing and Yang, Tianyu and Zhang, Yong and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2211.13221},
  year={2022}
}

@article{huang2024free,
  title={Free-bloom: Zero-shot text-to-video generator with llm director and ldm animator},
  author={Huang, Hanzhuo and Feng, Yufan and Shi, Cheng and Xu, Lan and Yu, Jingyi and Yang, Sibei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{li2023amt,
  title={Amt: All-pairs multi-field transforms for efficient frame interpolation},
  author={Li, Zhen and Zhu, Zuo-Liang and Han, Ling-Hao and Hou, Qibin and Guo, Chun-Le and Cheng, Ming-Ming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9801--9810},
  year={2023}
}

@article{choi2023custom,
  title={Custom-edit: Text-guided image editing with customized diffusion models},
  author={Choi, Jooyoung and Choi, Yunjey and Kim, Yunji and Kim, Junho and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2305.15779},
  year={2023}
}

@article{chen2023disenbooth,
  title={Disenbooth: Identity-preserving disentangled tuning for subject-driven text-to-image generation},
  author={Chen, Hong and Zhang, Yipeng and Wu, Simin and Wang, Xin and Duan, Xuguang and Zhou, Yuwei and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2305.03374},
  year={2023}
}

@inproceedings{jiang2024videobooth,
  title={Videobooth: Diffusion-based video generation with image prompts},
  author={Jiang, Yuming and Wu, Tianxing and Yang, Shuai and Si, Chenyang and Lin, Dahua and Qiao, Yu and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6689--6700},
  year={2024}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22500--22510},
  year={2023}
}

@inproceedings{mou2024t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4296--4304},
  year={2024}
}

@article{wang2023zero,
  title={Zero-shot video editing using off-the-shelf image diffusion models},
  author={Wang, Wen and Jiang, Yan and Xie, Kangyang and Liu, Zide and Chen, Hao and Cao, Yue and Wang, Xinlong and Shen, Chunhua},
  journal={arXiv preprint arXiv:2303.17599},
  year={2023}
}

@article{hong2022cogvideo,
  title={Cogvideo: Large-scale pretraining for text-to-video generation via transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}

@inproceedings{villegas2022phenaki,
  title={Phenaki: Variable length video generation from open domain textual descriptions},
  author={Villegas, Ruben and Babaeizadeh, Mohammad and Kindermans, Pieter-Jan and Moraldo, Hernan and Zhang, Han and Saffar, Mohammad Taghi and Castro, Santiago and Kunze, Julius and Erhan, Dumitru},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@article{an2023latent,
  title={Latent-shift: Latent diffusion with temporal shift for efficient text-to-video generation},
  author={An, Jie and Zhang, Songyang and Yang, Harry and Gupta, Sonal and Huang, Jia-Bin and Luo, Jiebo and Yin, Xi},
  journal={arXiv preprint arXiv:2304.08477},
  year={2023}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@inproceedings{tulyakov2018mocogan,
  title={Mocogan: Decomposing motion and content for video generation},
  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1526--1535},
  year={2018}
}

@article{he2024id,
  title={Id-animator: Zero-shot identity-preserving human video generation},
  author={He, Xuanhua and Liu, Quande and Qian, Shengju and Wang, Xin and Hu, Tao and Cao, Ke and Yan, Keyu and Zhang, Jie},
  journal={arXiv preprint arXiv:2404.15275},
  year={2024}
}

@article{yuan2024identity,
  title={Identity-Preserving Text-to-Video Generation by Frequency Decomposition},
  author={Yuan, Shenghai and Huang, Jinfa and He, Xianyi and Ge, Yunyuan and Shi, Yujun and Chen, Liuhan and Luo, Jiebo and Yuan, Li},
  journal={arXiv preprint arXiv:2411.17440},
  year={2024}
}